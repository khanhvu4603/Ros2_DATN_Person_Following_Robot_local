# üìö Ph√¢n T√≠ch Chi Ti·∫øt Thu·∫≠t To√°n DeepSORT trong Person Detector

> **T√°c gi·∫£**: AI Engineer  
> **Ng√†y**: 17/12/2024  
> **File ch√≠nh**: `person_detector.py` (895 d√≤ng)  
> **Sub-package**: `tracking/` (4 files)

---

## üìñ M·ª•c L·ª•c

1. [T·ªïng Quan Ki·∫øn Tr√∫c](#1-t·ªïng-quan-ki·∫øn-tr√∫c)
2. [State Machine (M√°y Tr·∫°ng Th√°i)](#2-state-machine-m√°y-tr·∫°ng-th√°i)
3. [DeepSORT Tracker](#3-deepsort-tracker)
4. [Kalman Filter](#4-kalman-filter)
5. [Track Management](#5-track-management)
6. [Matching Algorithm](#6-matching-algorithm)
7. [Feature Extraction (ReID)](#7-feature-extraction-reid)
8. [Lu·ªìng X·ª≠ L√Ω Chi Ti·∫øt](#8-lu·ªìng-x·ª≠-l√Ω-chi-ti·∫øt)
9. [Tham S·ªë C·∫•u H√¨nh](#9-tham-s·ªë-c·∫•u-h√¨nh)

---

## 1. T·ªïng Quan Ki·∫øn Tr√∫c

### 1.1 S∆° ƒê·ªì Ki·∫øn Tr√∫c T·ªïng Th·ªÉ

```mermaid
flowchart TB
    subgraph Input["üì∑ Input"]
        CAM[RealSense D455<br/>Color + Depth]
    end
    
    subgraph Detection["üîç Detection"]
        SSD[MobileNet-SSD<br/>Person Detection]
    end
    
    subgraph ReID["üéØ ReID Feature"]
        MB2[MobileNetV2<br/>1280-dim]
        HSV[HSV Histogram<br/>48-dim]
        DEPTH[Depth Feature<br/>256-dim]
        CONCAT[Concatenate<br/>1584-dim]
    end
    
    subgraph Tracking["üìç DeepSORT Tracker"]
        KF[Kalman Filter<br/>8-dim State]
        TRACK[Track Manager<br/>ID + Features]
        MATCH[Hungarian Matcher<br/>Cost Matrix]
    end
    
    subgraph State["üö¶ State Machine"]
        ENROLL[AUTO-ENROLL]
        SEARCH[SEARCHING]
        LOCK[LOCKED]
        LOST[LOST]
    end
    
    subgraph Output["üì§ Output"]
        CMD[/cmd_vel/]
        DEBUG[Debug Image]
        UDP[UDP Stream]
    end
    
    CAM --> SSD
    SSD --> ReID
    MB2 --> CONCAT
    HSV --> CONCAT
    DEPTH --> CONCAT
    CONCAT --> Tracking
    KF --> TRACK
    MATCH --> TRACK
    TRACK --> State
    State --> Output
```

### 1.2 C√°c Th√†nh Ph·∫ßn Ch√≠nh

| Th√†nh ph·∫ßn | File | Ch·ª©c nƒÉng |
|------------|------|-----------|
| **PersonDetector** | `person_detector.py` | ROS2 Node ch√≠nh, x·ª≠ l√Ω state machine |
| **DeepSORTTracker** | `tracking/tracker.py` | ƒêi·ªÅu ph·ªëi tracking, matching, track lifecycle |
| **KalmanFilter** | `tracking/kalman_filter.py` | D·ª± ƒëo√°n v·ªã tr√≠ b·∫±ng motion model |
| **Track** | `tracking/track.py` | L∆∞u tr·∫°ng th√°i v√† feature c·ªßa m·ªói target |
| **nn_matching** | `tracking/nn_matching.py` | Cost matrix v√† Hungarian matching |

---

## 2. State Machine (M√°y Tr·∫°ng Th√°i) - PH√ÇN T√çCH CHI TI·∫æT

### 2.1 T·ªïng Quan 4 Tr·∫°ng Th√°i

| Tr·∫°ng th√°i | M·ª•c ƒë√≠ch | Robot h√†nh vi | Th·ªùi gian |
|------------|----------|---------------|-----------|
| **AUTO-ENROLL** | Thu th·∫≠p ƒë·∫∑c tr∆∞ng target | ƒê·ª©ng y√™n | 30s ho·∫∑c 100 samples |
| **SEARCHING** | T√¨m ki·∫øm target | C√≥ th·ªÉ xoay | Kh√¥ng gi·ªõi h·∫°n |
| **LOCKED** | ƒêang follow target | Di chuy·ªÉn theo | Li√™n t·ª•c |
| **LOST** | T·∫°m m·∫•t target | ƒê·ª©ng y√™n/ch·∫≠m | Max 2s (grace period) |

### 2.2 S∆° ƒê·ªì Chuy·ªÉn Tr·∫°ng Th√°i Chi Ti·∫øt

```mermaid
stateDiagram-v2
    [*] --> AUTO_ENROLL: üöÄ Kh·ªüi ƒë·ªông node
    
    AUTO_ENROLL --> SEARCHING: ‚úÖ ƒê·ªß 100 samples<br/>HO·∫∂C timeout 30s
    
    SEARCHING --> LOCKED: üéØ T√¨m th·∫•y confirmed track<br/>c√≥ similarity > 0.75
    
    LOCKED --> LOST: ‚ö†Ô∏è Occlusion detected<br/>HO·∫∂C similarity < 0.60<br/>HO·∫∂C track b·ªã x√≥a
    LOCKED --> LOCKED: ‚úÖ Track OK + similarity > 0.60
    
    LOST --> LOCKED: üîÑ Track matched l·∫°i<br/>+ similarity > 0.75
    LOST --> SEARCHING: ‚è∞ Grace period 2s h·∫øt<br/>+ kh√¥ng t√¨m ƒë∆∞·ª£c target
    
    note right of AUTO_ENROLL
        üìç V·ªã tr√≠ b·∫Øt ƒë·∫ßu
        üéµ Ph√°t audio h∆∞·ªõng d·∫´n
        üì∏ Thu 100 body samples
        üìä T√≠nh target_feature centroid
    end note
    
    note right of SEARCHING
        üîç T√¨m trong confirmed tracks
        üéµ Ph√°t √¢m thanh "m·∫•t target"
        üîÑ Li√™n t·ª•c ƒë·∫øn khi t√¨m ƒë∆∞·ª£c
    end note
    
    note right of LOCKED
        üìç Follow target b·∫±ng track_id
        üîÆ Kalman Filter c·∫≠p nh·∫≠t v·ªã tr√≠
        üìà Adaptive model update
        üéµ T·∫Øt √¢m thanh m·∫•t target
    end note
    
    note right of LOST
        üîÆ Kalman Filter d·ª± ƒëo√°n v·ªã tr√≠
        üîÑ Th·ª≠ re-acquire b·∫±ng ReID
        ‚è∞ Ch·ªù max 2 gi√¢y
    end note
```

---

### 2.3 Chi Ti·∫øt T·ª´ng Tr·∫°ng Th√°i

---

#### üü¢ **AUTO-ENROLL** - Giai ƒëo·∫°n ƒëƒÉng k√Ω target

**File**: `person_detector.py` d√≤ng 413-445, 723-742

**M·ª•c ƒë√≠ch**: Thu th·∫≠p ƒë·∫∑c tr∆∞ng ngo·∫°i h√¨nh c·ªßa target ƒë·ªÉ l√†m m·∫´u so s√°nh sau n√†y.

**ƒêi·ªÅu ki·ªán v√†o**:
- Node v·ª´a kh·ªüi ƒë·ªông (`self.auto_done = False`)

**Ho·∫°t ƒë·ªông trong tr·∫°ng th√°i**:

```python
def auto_enroll_step(self, frame, pboxes):
    # 1. Ch·ªçn person box L·ªöN NH·∫§T trong frame
    #    (Gi·∫£ ƒë·ªãnh ng∆∞·ªùi ƒë·ª©ng g·∫ßn nh·∫•t l√† target)
    j = int(np.argmax([(pb[2]-pb[0])*(pb[3]-pb[1]) for pb in pboxes]))
    pb = pboxes[j]
    
    # 2. Tr√≠ch xu·∫•t feature t·ª´ person box
    feat = enhanced_body_feature(frame, pb, self.depth_img, self.mb2_sess, ...)
    #    ‚Üí Vector 1584-dim (MobileNetV2 + HSV + Depth)
    
    # 3. L∆∞u v√†o danh s√°ch samples
    self.body_samples.append(feat)
    
    # 4. C·∫≠p nh·∫≠t centroid b·∫±ng EMA (Exponential Moving Average)
    if self.body_centroid is None:
        self.body_centroid = feat.copy()
    else:
        self.body_centroid = 0.9 * self.body_centroid + 0.1 * feat
        #                    ‚Üë 90% c≈© + 10% m·ªõi ‚Üí ·ªîn ƒë·ªãnh, gi·∫£m noise
        self.body_centroid /= (np.linalg.norm(self.body_centroid) + 1e-8)
```

**ƒêi·ªÅu ki·ªán chuy·ªÉn ‚Üí SEARCHING**:

| ƒêi·ªÅu ki·ªán | Gi·∫£i th√≠ch |
|-----------|------------|
| `len(body_samples) >= 100` | ƒê√£ thu ƒë·ªß 100 m·∫´u |
| `(now - auto_start_ts) >= 30s` | Timeout 30 gi√¢y |

```python
if (now - self.auto_start_ts) >= timeout or len(self.body_samples) >= body_target:
    if self.body_centroid is not None:
        self.target_feature = self.body_centroid.copy()  # L∆∞u l√†m template
    self.auto_done = True
    self.state = 'SEARCHING'  # ‚Üê Chuy·ªÉn tr·∫°ng th√°i
    
    # Ph√°t √¢m thanh th√¥ng b√°o b·∫Øt ƒë·∫ßu ch·∫°y
    os.system(f"aplay {self.run_sound_file} &")
```

**T·∫°i sao c·∫ßn AUTO-ENROLL?**
- C·∫ßn c√≥ "m·∫´u" c·ªßa target tr∆∞·ªõc khi t√¨m ki·∫øm
- 100 samples t·ª´ nhi·ªÅu g√≥c ƒë·ªô ‚Üí feature ·ªïn ƒë·ªãnh h∆°n
- Centroid (trung b√¨nh) gi·∫£m nhi·ªÖu t·ª´ single sample

---

#### üîµ **SEARCHING** - T√¨m ki·∫øm target

**File**: `person_detector.py` d√≤ng 760-770

**M·ª•c ƒë√≠ch**: T√¨m l·∫°i target sau khi m·∫•t ho√†n to√†n (h·∫øt grace period).

**ƒêi·ªÅu ki·ªán v√†o**:
| T·ª´ tr·∫°ng th√°i | ƒêi·ªÅu ki·ªán |
|---------------|-----------|
| AUTO-ENROLL | Thu th·∫≠p xong features |
| LOST | Grace period 2s h·∫øt m√† kh√¥ng t√¨m ƒë∆∞·ª£c |

**Ho·∫°t ƒë·ªông trong tr·∫°ng th√°i**:

```python
if self.state == 'SEARCHING':
    # 1. L·∫•y t·∫•t c·∫£ confirmed tracks t·ª´ DeepSORT
    confirmed_tracks = self.deepsort.get_confirmed_tracks()
    
    # 2. T√¨m track c√≥ similarity CAO NH·∫§T v·ªõi target_feature
    best_track = self._find_best_track_by_reid(confirmed_tracks)
```

**H√†m `_find_best_track_by_reid` ho·∫°t ƒë·ªông nh∆∞ sau**:

```python
def _find_best_track_by_reid(self, tracks):
    best_track = None
    best_score = -1.0
    
    for track in tracks:
        # Ch·ªâ x√©t confirmed tracks
        if not track.is_confirmed():
            continue
        
        # L·∫•y feature trung b√¨nh t·ª´ track history
        track_feature = track.get_feature()  # Mean c·ªßa 30 samples g·∫ßn nh·∫•t
        if track_feature is None:
            continue
        
        # T√≠nh cosine similarity
        score = float(np.dot(track_feature, self.target_feature))
        #       ‚Üë Dot product c·ªßa 2 L2-normalized vectors = cosine similarity
        #       Range: [-1, 1], c√†ng cao c√†ng gi·ªëng
        
        if score > best_score:
            best_score = score
            best_track = track
    
    # Ch·ªâ ch·∫•p nh·∫≠n n·∫øu v∆∞·ª£t ng∆∞·ª°ng
    accept_thr = 0.75  # T·ª´ parameter 'accept_threshold'
    if best_score > accept_thr:
        self.current_similarity = best_score
        return best_track
    
    return None  # Kh√¥ng t√¨m th·∫•y
```

**ƒêi·ªÅu ki·ªán chuy·ªÉn ‚Üí LOCKED**:

```python
if best_track is not None:  # T√¨m ƒë∆∞·ª£c track c√≥ similarity > 0.75
    self.state = 'LOCKED'
    self.current_track_id = best_track.track_id  # L∆∞u ID ƒë·ªÉ follow
    self.target_box = tuple(map(int, best_track.to_tlbr()))
    self.stop_lost_sound_loop()  # T·∫Øt √¢m thanh "m·∫•t target"
```

**T·∫°i sao c·∫ßn ng∆∞·ª°ng 0.75?**
- Qu√° th·∫•p ‚Üí D·ªÖ lock nh·∫ßm ng∆∞·ªùi kh√°c
- Qu√° cao ‚Üí Kh√≥ t√¨m ƒë∆∞·ª£c target (d√π ƒë√∫ng ng∆∞·ªùi)
- 0.75 l√† c√¢n b·∫±ng gi·ªØa precision v√† recall

---

#### üü° **LOCKED** - ƒêang follow target

**File**: `person_detector.py` d√≤ng 772-826

**M·ª•c ƒë√≠ch**: Robot ƒëang follow target ·ªïn ƒë·ªãnh.

**ƒêi·ªÅu ki·ªán v√†o**:
| T·ª´ tr·∫°ng th√°i | ƒêi·ªÅu ki·ªán |
|---------------|-----------|
| SEARCHING | T√¨m ƒë∆∞·ª£c track c√≥ similarity > 0.75 |
| LOST | Track matched l·∫°i + similarity > 0.75 |

**Ho·∫°t ƒë·ªông trong tr·∫°ng th√°i (theo th·ª© t·ª±)**:

```python
elif self.state == 'LOCKED':
    
    # ========== B∆Ø·ªöC 1: Ki·ªÉm tra OCCLUSION ==========
    if self.is_target_occluded(self.target_box, depth_frame, self.last_known_depth):
        # Target b·ªã che b·ªüi v·∫≠t th·ªÉ ·ªü g·∫ßn h∆°n
        self.state = 'LOST'  # ‚Üê Chuy·ªÉn ngay l·∫≠p t·ª©c
        self.lost_start_time = time.time()
        return
```

**Ki·ªÉm tra occlusion b·∫±ng depth**:

```python
def is_target_occluded(self, target_box, depth_img, last_known_depth):
    current_depth = self.get_median_depth_at_box(target_box, depth_img)
    
    threshold = 0.5  # 50cm
    
    # N·∫øu depth hi·ªán t·∫°i NH·ªé h∆°n nhi·ªÅu so v·ªõi depth tr∆∞·ªõc ƒë√≥
    # ‚Üí C√≥ v·∫≠t g√¨ ƒë√≥ ƒë·ª©ng gi·ªØa camera v√† target
    if current_depth < (last_known_depth - threshold):
        return True  # B·ªã che!
    
    return False
```

**V√≠ d·ª•**:
- Target c√°ch camera 2.5m (`last_known_depth = 2.5`)
- Ai ƒë√≥ ƒëi ngang qua ·ªü 1.5m
- `current_depth = 1.5 < 2.5 - 0.5 = 2.0` ‚Üí **Occlusion detected!**

```python
    # ========== B∆Ø·ªöC 2: L·∫•y track theo ID ==========
    target_track = self.deepsort.get_track_by_id(self.current_track_id)
    reject_thr = 0.60  # T·ª´ parameter 'reject_threshold'
    
    if target_track is not None and not target_track.is_deleted():
        # Track v·∫´n t·ªìn t·∫°i trong DeepSORT
        
        # 2.1 C·∫≠p nh·∫≠t target_box t·ª´ track
        self.target_box = tuple(map(int, target_track.to_tlbr()))
        self.last_known_depth = self.get_median_depth_at_box(...)
        
        # 2.2 T√≠nh similarity ƒë·ªÉ validate
        track_feature = target_track.get_feature()
        self.current_similarity = float(np.dot(track_feature, self.target_feature))
```

```python
        # ========== B∆Ø·ªöC 3: Adaptive Model Update ==========
        # Ch·ªâ update model khi:
        # - similarity > reject_thr (ƒë√∫ng ng∆∞·ªùi)
        # - similarity < 0.7 (c√≥ s·ª± thay ƒë·ªïi, c·∫ßn adapt)
        # - ƒê√£ qua 1 gi√¢y k·ªÉ t·ª´ l·∫ßn update tr∆∞·ªõc
        
        if (self.current_similarity > reject_thr and 
            self.current_similarity < 0.7 and
            now - self.last_update_time > 1.0):
            self.adaptive_model_update(self.target_box, frame, depth_frame)
            self.last_update_time = now
```

**ƒêi·ªÅu ki·ªán chuy·ªÉn ‚Üí LOST**:

```python
        # ========== B∆Ø·ªöC 4: Ki·ªÉm tra similarity ==========
        if self.current_similarity < reject_thr:  # < 0.60
            self.get_logger().info(f"Track similarity too low ({self.current_similarity:.2f})")
            self.state = 'LOST'
            self.lost_start_time = time.time()
```

```python
    else:
        # ========== B∆Ø·ªöC 5: Track kh√¥ng c√≤n t·ªìn t·∫°i ==========
        # DeepSORT ƒë√£ x√≥a track (qu√° l√¢u kh√¥ng match)
        # Th·ª≠ t√¨m b·∫±ng ReID trong c√°c tracks kh√°c
        
        best_track = self._find_best_track_by_reid(confirmed_tracks)
        if best_track is not None:
            # T√¨m ƒë∆∞·ª£c track thay th·∫ø ‚Üí g√°n ID m·ªõi
            self.current_track_id = best_track.track_id
            self.target_box = tuple(map(int, best_track.to_tlbr()))
        else:
            # Kh√¥ng t√¨m ƒë∆∞·ª£c ‚Üí LOST
            self.state = 'LOST'
            self.lost_start_time = time.time()
```

**B·∫£ng t·ªïng h·ª£p ƒëi·ªÅu ki·ªán chuy·ªÉn t·ª´ LOCKED**:

| ƒêi·ªÅu ki·ªán | K·∫øt qu·∫£ | Gi·∫£i th√≠ch |
|-----------|---------|------------|
| Occlusion detected | ‚Üí LOST | C√≥ v·∫≠t che ·ªü g·∫ßn h∆°n |
| similarity < 0.60 | ‚Üí LOST | C√≥ th·ªÉ nh·∫ßm ng∆∞·ªùi |
| Track b·ªã x√≥a + kh√¥ng t√¨m ƒë∆∞·ª£c b·∫±ng ReID | ‚Üí LOST | M·∫•t ho√†n to√†n |
| Track b·ªã x√≥a + t√¨m ƒë∆∞·ª£c b·∫±ng ReID | Gi·ªØ LOCKED | G√°n track_id m·ªõi |
| similarity >= 0.60 + track OK | Gi·ªØ LOCKED | Ti·∫øp t·ª•c follow |

---

#### üî¥ **LOST** - T·∫°m m·∫•t target

**File**: `person_detector.py` d√≤ng 828-868

**M·ª•c ƒë√≠ch**: C·ªë g·∫Øng t√¨m l·∫°i target trong th·ªùi gian ng·∫Øn (grace period).

**ƒêi·ªÅu ki·ªán v√†o**:
| T·ª´ tr·∫°ng th√°i | ƒêi·ªÅu ki·ªán |
|---------------|-----------|
| LOCKED | Occlusion HO·∫∂C similarity < 0.60 HO·∫∂C track b·ªã x√≥a |

**T·∫°i sao c·∫ßn LOST state thay v√¨ SEARCHING ngay?**
- **Kalman Filter** v·∫´n c√≥ th·ªÉ predict v·ªã tr√≠ target ngay c·∫£ khi detection m·∫•t
- Cho c∆° h·ªôi **re-acquire** nhanh n·∫øu target quay l·∫°i trong frame
- Tr√°nh **nh·∫£y lung tung** gi·ªØa c√°c ng∆∞·ªùi khi c√≥ occlusion t·∫°m th·ªùi

**Ho·∫°t ƒë·ªông trong tr·∫°ng th√°i**:

```python
elif self.state == 'LOST':
    
    # ========== B∆Ø·ªöC 1: L·∫•y track prediction t·ª´ Kalman ==========
    target_track = self.deepsort.get_track_by_id(self.current_track_id)
    
    if target_track is not None and not target_track.is_deleted():
        # Track v·∫´n c√≤n trong DeepSORT (ch∆∞a qu√° max_age = 30 frames)
        
        # L·∫•y v·ªã tr√≠ D·ª∞ ƒêO√ÅN t·ª´ Kalman Filter
        self.target_box = tuple(map(int, target_track.to_tlbr()))
        # ‚Üí Robot v·∫´n bi·∫øt target "c√≥ th·ªÉ" ·ªü ƒë√¢u
```

```python
        # ========== B∆Ø·ªöC 2: Ki·ªÉm tra re-match ==========
        if target_track.time_since_update == 0:
            # Track v·ª´a ƒë∆∞·ª£c match v·ªõi detection m·ªõi!
            # ‚Üí C√≥ th·ªÉ target ƒë√£ quay l·∫°i
            
            track_feature = target_track.get_feature()
            score = float(np.dot(track_feature, self.target_feature))
            accept_thr = 0.75
            
            if score > accept_thr:
                self.state = 'LOCKED'  # ‚Üê Re-acquire th√†nh c√¥ng!
                self.current_similarity = score
                self.stop_lost_sound_loop()
```

**`time_since_update` l√† g√¨?**

| Gi√° tr·ªã | √ù nghƒ©a |
|---------|---------|
| 0 | Track v·ª´a ƒë∆∞·ª£c match v·ªõi detection ·ªü frame n√†y |
| 1 | Track kh√¥ng match ·ªü frame n√†y, d√πng Kalman predict |
| 2, 3, ... | S·ªë frame li√™n ti·∫øp kh√¥ng match |
| > max_age (30) | Track b·ªã x√≥a |

```python
    else:
        # ========== B∆Ø·ªöC 3: Track ƒë√£ b·ªã x√≥a, th·ª≠ ReID ==========
        best_track = self._find_best_track_by_reid(confirmed_tracks)
        if best_track is not None:
            self.state = 'LOCKED'
            self.current_track_id = best_track.track_id
            self.stop_lost_sound_loop()
```

```python
    # ========== B∆Ø·ªöC 4: Check Grace Period ==========
    if self.lost_start_time is not None:
        elapsed = time.time() - self.lost_start_time
        grace_period = 2.0  # seconds
        
        if elapsed > grace_period:
            # ƒê√£ ch·ªù 2 gi√¢y m√† kh√¥ng t√¨m ƒë∆∞·ª£c
            self.state = 'SEARCHING'  # ‚Üê Reset v·ªÅ SEARCHING
            self.target_box = None
            self.current_track_id = None
            self.start_lost_sound_loop()  # Ph√°t √¢m thanh "m·∫•t target"
```

**B·∫£ng t·ªïng h·ª£p ƒëi·ªÅu ki·ªán chuy·ªÉn t·ª´ LOST**:

| ƒêi·ªÅu ki·ªán | K·∫øt qu·∫£ | Gi·∫£i th√≠ch |
|-----------|---------|------------|
| Track match l·∫°i + similarity > 0.75 | ‚Üí LOCKED | Re-acquire nhanh |
| T√¨m ƒë∆∞·ª£c b·∫±ng ReID | ‚Üí LOCKED | Chuy·ªÉn sang track m·ªõi |
| Grace period 2s h·∫øt | ‚Üí SEARCHING | Reset ho√†n to√†n |
| Ch∆∞a t√¨m ƒë∆∞·ª£c + ch∆∞a h·∫øt grace | Gi·ªØ LOST | Ti·∫øp t·ª•c th·ª≠ |

---

### 2.4 S∆° ƒê·ªì Timeline V√≠ D·ª•

```
Time (frames): 0   10   20   30   40   50   60   70   80   90  100  110  120
                |    |    |    |    |    |    |    |    |    |    |    |    |
State:      [AUTO-ENROLL]  [SEARCHING] [      LOCKED      ] [LOST][  LOCKED  ]
                  ‚Üë              ‚Üë           ‚Üë         ‚Üë      ‚Üë        ‚Üë
                  |              |           |         |      |        |
           Thu 100 samples   T√¨m ƒë∆∞·ª£c    Follow    B·ªã che  Grace   Re-acquire
                           target         OK       khu·∫•t   2s OK
```

**Gi·∫£i th√≠ch timeline**:
1. **Frame 0-30**: AUTO-ENROLL - Thu th·∫≠p 100 samples
2. **Frame 30-40**: SEARCHING - T√¨m ki·∫øm trong confirmed tracks
3. **Frame 40-70**: LOCKED - Follow ·ªïn ƒë·ªãnh
4. **Frame 70**: C√≥ ng∆∞·ªùi ƒëi ngang che khu·∫•t ‚Üí LOST
5. **Frame 70-90**: LOST - Kalman predict, ch·ªù re-acquire
6. **Frame 90**: Ng∆∞·ªùi ƒëi ngang ƒë√£ ƒëi qua, target xu·∫•t hi·ªán l·∫°i
7. **Frame 90+**: LOCKED - Ti·∫øp t·ª•c follow

---

### 2.5 So S√°nh Ng∆∞·ª°ng (Thresholds)

| Ng∆∞·ª°ng | Gi√° tr·ªã | S·ª≠ d·ª•ng t·∫°i | M·ª•c ƒë√≠ch |
|--------|---------|-------------|----------|
| **accept_threshold** | 0.75 | SEARCHING ‚Üí LOCKED | C·∫ßn ch·∫Øc ch·∫Øn l√† ƒë√∫ng target |
| | | LOST ‚Üí LOCKED | |
| **reject_threshold** | 0.60 | LOCKED (validation) | Cho ph√©p bi·∫øn ƒë·ªïi nh·∫π |
| **occlusion_threshold** | 0.5m | LOCKED (depth check) | Ph√°t hi·ªán che khu·∫•t |
| **grace_period** | 2.0s | LOST ‚Üí SEARCHING | Th·ªùi gian ch·ªù |

**T·∫°i sao accept > reject?**
- `accept` c·∫ßn **cao** (0.75) ƒë·ªÉ tr√°nh lock nh·∫ßm ng∆∞·ªùi
- `reject` c√≥ th·ªÉ **th·∫•p h∆°n** (0.60) v√¨:
  - Target ƒë√£ ƒë∆∞·ª£c x√°c nh·∫≠n tr∆∞·ªõc ƒë√≥
  - Cho ph√©p bi·∫øn ƒë·ªïi nh·∫π (g√≥c nh√¨n, √°nh s√°ng)
  - Tr√°nh m·∫•t target do dao ƒë·ªông similarity

---

### 2.6 C√°c Bi·∫øn Quan Tr·ªçng

| Bi·∫øn | Kh·ªüi t·∫°o | M√¥ t·∫£ |
|------|----------|-------|
| `self.state` | 'AUTO-ENROLL' | Tr·∫°ng th√°i hi·ªán t·∫°i |
| `self.target_feature` | None | Vector 1584-dim c·ªßa target |
| `self.current_track_id` | None | ID c·ªßa track ƒëang follow |
| `self.target_box` | None | Bounding box hi·ªán t·∫°i |
| `self.lost_start_time` | None | Th·ªùi ƒëi·ªÉm v√†o LOST |
| `self.current_similarity` | 0.0 | Similarity score hi·ªán t·∫°i |
| `self.last_known_depth` | None | Depth cu·ªëi c√πng c·ªßa target |

---

## 3. DeepSORT Tracker

### 3.1 T·ªïng Quan DeepSORTTracker

**File**: `tracking/tracker.py`

```python
class DeepSORTTracker:
    def __init__(self, max_age=30, n_init=3, max_cosine_distance=0.4, lambda_weight=0.3):
        self.max_age = max_age          # S·ªë frame gi·ªØ track khi m·∫•t
        self.n_init = n_init            # S·ªë hits ƒë·ªÉ confirm track
        self.max_cosine_distance = 0.4  # Ng∆∞·ª°ng appearance matching
        self.lambda_weight = 0.3        # Motion vs Appearance weight
        
        self.kf = KalmanFilter()        # Kalman Filter instance
        self.tracks = []                # Danh s√°ch tracks
        self._next_id = 1               # ID counter
```

### 3.2 Lu·ªìng Update

```mermaid
sequenceDiagram
    participant PD as PersonDetector
    participant DS as DeepSORTTracker
    participant KF as KalmanFilter
    participant T as Track
    
    PD->>DS: update(detections, features)
    
    Note over DS: 1. PREDICT
    DS->>KF: predict() cho m·ªói track
    KF->>T: C·∫≠p nh·∫≠t mean, covariance
    
    Note over DS: 2. MATCH
    DS->>DS: _match_confirmed()
    DS->>DS: _match_iou()
    
    Note over DS: 3. UPDATE
    loop Matched tracks
        DS->>KF: update(measurement)
        DS->>T: Add feature
    end
    
    Note over DS: 4. CREATE
    loop Unmatched detections
        DS->>T: Create new Track
    end
    
    Note over DS: 5. CLEANUP
    DS->>DS: Remove deleted tracks
    
    DS->>PD: return active tracks
```

### 3.3 Cascade Matching

DeepSORT s·ª≠ d·ª•ng **2 giai ƒëo·∫°n matching**:

#### Stage 1: Match Confirmed Tracks (Appearance + Motion)

```python
def _match_confirmed(self, detections, features, track_indices):
    # 1. Appearance cost (cosine distance)
    appearance_cost = appearance_cost(tracks, features, ...)
    
    # 2. Motion cost (IoU as proxy)
    iou_cost = iou_cost(tracks, detections, ...)
    
    # 3. Combined cost
    cost = lambda * iou_cost + (1-lambda) * appearance_cost
    
    # 4. Kalman gating (lo·∫°i b·ªè matches kh√¥ng h·ª£p l√Ω v·ªÅ motion)
    cost = gate_cost_matrix(kf, cost, tracks, detections, ...)
    
    # 5. Appearance threshold
    cost[appearance_cost > max_cosine_distance] = INFTY
    
    # 6. Hungarian matching
    matches = min_cost_matching(cost)
    return matches
```

#### Stage 2: Match Tentative Tracks (IoU only)

```python
def _match_iou(self, detections, track_indices, detection_indices):
    iou_cost = iou_cost(tracks, detections, ...)
    matches = min_cost_matching(iou_cost, max_distance=0.7)  # IoU > 0.3
    return matches
```

**T·∫°i sao 2 giai ƒëo·∫°n?**
- Confirmed tracks: C·∫ßn c·∫£ motion v√† appearance ƒë·ªÉ matching ch√≠nh x√°c
- Tentative tracks: Ch∆∞a ƒë·ªß feature history, ch·ªâ d√πng IoU

---

## 4. Kalman Filter

### 4.1 State Space Model

**File**: `tracking/kalman_filter.py`

**State Vector (8-dim)**:
```
x = [cx, cy, a, h, vx, vy, va, vh]
```

| Index | Variable | √ù nghƒ©a |
|-------|----------|---------|
| 0 | `cx` | T√¢m X c·ªßa bounding box |
| 1 | `cy` | T√¢m Y c·ªßa bounding box |
| 2 | `a` | Aspect ratio (width/height) |
| 3 | `h` | Height c·ªßa bounding box |
| 4 | `vx` | V·∫≠n t·ªëc X |
| 5 | `vy` | V·∫≠n t·ªëc Y |
| 6 | `va` | T·ªëc ƒë·ªô thay ƒë·ªïi aspect ratio |
| 7 | `vh` | T·ªëc ƒë·ªô thay ƒë·ªïi height |

**Measurement Vector (4-dim)**:
```
z = [cx, cy, a, h]
```

### 4.2 Ph∆∞∆°ng Tr√¨nh Kalman

#### Prediction Step

```python
def predict(self, mean, covariance):
    # State transition: x' = F * x
    # F = Motion Matrix (constant velocity model)
    #     [1 0 0 0 dt 0  0  0 ]
    #     [0 1 0 0 0  dt 0  0 ]
    #     [0 0 1 0 0  0  dt 0 ]
    # F = [0 0 0 1 0  0  0  dt]
    #     [0 0 0 0 1  0  0  0 ]
    #     [0 0 0 0 0  1  0  0 ]
    #     [0 0 0 0 0  0  1  0 ]
    #     [0 0 0 0 0  0  0  1 ]
    
    mean = F @ mean
    covariance = F @ covariance @ F.T + Q  # Q = process noise
    return mean, covariance
```

**Gi·∫£i th√≠ch**: 
- T√¢m m·ªõi = T√¢m c≈© + V·∫≠n t·ªëc √ó dt
- V·∫≠n t·ªëc gi·∫£ ƒë·ªãnh kh√¥ng ƒë·ªïi (constant velocity model)

#### Update Step

```python
def update(self, mean, covariance, measurement):
    # Projection to measurement space: H * x
    # H = [1 0 0 0 0 0 0 0]
    #     [0 1 0 0 0 0 0 0]
    #     [0 0 1 0 0 0 0 0]
    #     [0 0 0 1 0 0 0 0]
    
    projected_mean = H @ mean
    projected_cov = H @ covariance @ H.T + R  # R = measurement noise
    
    # Kalman gain
    K = covariance @ H.T @ inv(projected_cov)
    
    # Innovation (residual)
    innovation = measurement - projected_mean
    
    # Update
    new_mean = mean + K @ innovation
    new_covariance = covariance - K @ projected_cov @ K.T
    
    return new_mean, new_covariance
```

### 4.3 Gating Distance

**Mahalanobis Distance** ƒë·ªÉ ki·ªÉm tra xem detection c√≥ ph√π h·ª£p v·ªõi track kh√¥ng:

```python
def gating_distance(self, mean, covariance, measurements):
    # Project state to measurement space
    mean, covariance = self.project(mean, covariance)
    
    # Cholesky decomposition
    L = cholesky(covariance)
    
    # Solve L * z = (measurement - mean)
    d = measurements - mean
    z = solve_triangular(L, d)
    
    # Squared Mahalanobis distance
    squared_maha = sum(z * z)
    
    return squared_maha
```

**Chi-square Gating**: N·∫øu `squared_maha > chi2inv95[4]` ‚Üí lo·∫°i b·ªè match

| DoF | Chi-square 95% |
|-----|----------------|
| 2 | 5.99 |
| 4 | 9.49 |

---

## 5. Track Management

### 5.1 Track Class

**File**: `tracking/track.py`

```python
class Track:
    def __init__(self, mean, covariance, track_id, n_init, max_age, feature):
        self.mean = mean           # Kalman state [8]
        self.covariance = cov      # Kalman covariance [8x8]
        self.track_id = track_id   # Unique ID
        
        self.hits = 1              # S·ªë l·∫ßn matched
        self.age = 1               # S·ªë frame k·ªÉ t·ª´ creation
        self.time_since_update = 0 # S·ªë frame k·ªÉ t·ª´ last match
        
        self.state = TrackState.Tentative
        self.features = [feature]  # Feature history (max 30)
```

### 5.2 Track Lifecycle

```mermaid
stateDiagram-v2
    [*] --> Tentative: New detection
    
    Tentative --> Confirmed: hits >= n_init (3)
    Tentative --> Deleted: No match (1 frame)
    
    Confirmed --> Confirmed: Matched
    Confirmed --> Deleted: time_since_update > max_age (30)
    
    Deleted --> [*]
    
    note right of Tentative
        M·ªõi t·∫°o, ch∆∞a ƒë·ªß tin c·∫≠y
        Ch·ªâ d√πng IoU matching
    end note
    
    note right of Confirmed
        ƒê√£ x√°c nh·∫≠n l√† real target
        D√πng appearance + motion
    end note
```

### 5.3 Feature History

```python
def update(self, kf, detection, feature):
    # Kalman update
    self.mean, self.covariance = kf.update(self.mean, self.covariance, detection)
    
    # Add feature to history
    if feature is not None:
        self.features.append(feature)
        # Keep only last 30 features
        if len(self.features) > 30:
            self.features = self.features[-30:]
    
    self.hits += 1
    self.time_since_update = 0
    
    # State transition
    if self.state == Tentative and self.hits >= n_init:
        self.state = Confirmed

def get_feature(self):
    # Return mean of feature history
    if len(self.features) == 0:
        return None
    return np.mean(self.features, axis=0)
```

**T·∫°i sao l∆∞u feature history?**
- Target c√≥ th·ªÉ thay ƒë·ªïi ngo·∫°i h√¨nh theo th·ªùi gian (g√≥c nh√¨n, √°nh s√°ng)
- Mean c·ªßa nhi·ªÅu samples ·ªïn ƒë·ªãnh h∆°n single sample
- Gi√∫p matching robust h∆°n trong occlusion

---

## 6. Matching Algorithm

### 6.1 Cost Matrix Construction

**File**: `tracking/nn_matching.py`

#### Appearance Cost (Cosine Distance)

```python
def _nn_cosine_distance(track_features, detection_feature):
    """
    T√¨m min cosine distance gi·ªØa detection v√† t·∫•t c·∫£ features trong track history
    """
    distances = []
    for feat in track_features:
        # Normalize
        feat = feat / (norm(feat) + 1e-8)
        detection_feature = detection_feature / (norm(detection_feature) + 1e-8)
        
        # Cosine distance = 1 - cosine similarity
        dist = 1.0 - np.dot(feat, detection_feature)
        distances.append(dist)
    
    return min(distances)  # Nearest neighbor
```

**Gi·∫£i th√≠ch**:
- Cosine similarity = 1.0: Ho√†n to√†n gi·ªëng nhau
- Cosine similarity = 0.0: Vu√¥ng g√≥c (kh√¥ng li√™n quan)
- Cosine distance = 1 - similarity: Nh·ªè ‚Üí gi·ªëng

#### IoU Cost

```python
def iou_cost(tracks, detections):
    for track in tracks:
        track_tlwh = track.to_tlwh()  # [top-left-x, top-left-y, width, height]
        for detection in detections:
            iou_score = iou(track_tlwh, detection)
            cost[track, detection] = 1.0 - iou_score  # IoU cao ‚Üí cost th·∫•p
```

#### Combined Cost

```python
cost = lambda_weight * iou_cost + (1 - lambda_weight) * appearance_cost
# lambda_weight = 0.3
# ‚Üí 30% motion (IoU) + 70% appearance
```

### 6.2 Hungarian Algorithm

```python
from scipy.optimize import linear_sum_assignment

def min_cost_matching(cost_matrix, max_distance):
    # Hungarian algorithm
    row_indices, col_indices = linear_sum_assignment(cost_matrix)
    
    matches = []
    unmatched_tracks = []
    unmatched_detections = []
    
    for row, col in zip(row_indices, col_indices):
        if cost_matrix[row, col] > max_distance:
            unmatched_tracks.append(row)
            unmatched_detections.append(col)
        else:
            matches.append((row, col))
    
    return matches, unmatched_tracks, unmatched_detections
```

**Hungarian Algorithm** t√¨m matching t·ªëi ∆∞u (minimize total cost) trong O(n¬≥).

---

## 7. Feature Extraction (ReID)

### 7.1 Enhanced Body Feature

**File**: `person_detector.py` (D√≤ng 167-194)

```python
def enhanced_body_feature(frame, box, depth_img, ort_sess, color_weight=0.3):
    """
    K·∫øt h·ª£p 3 lo·∫°i ƒë·∫∑c tr∆∞ng:
    1. MobileNetV2 embedding (1280-dim) - H√¨nh d·∫°ng c∆° th·ªÉ
    2. HSV histogram (48-dim) - M√†u s·∫Øc qu·∫ßn √°o
    3. Depth feature (256-dim) - H√¨nh d·∫°ng 3D
    """
    
    # === 1. MobileNetV2 Feature (1280-dim) ===
    roi_padded, _ = body_arr_preserve_aspect_ratio(frame, box)  # Resize to 224x224
    roi_rgb = cv2.cvtColor(roi_padded, cv2.COLOR_BGR2RGB)
    arr = mb2_preprocess_keras_style(roi_rgb)  # [-1, 1] normalization
    emb = ort_sess.run(None, {inp_name: arr})[0].flatten()  # 1280-dim
    emb /= np.linalg.norm(emb)  # L2 normalize
    
    # === 2. HSV Histogram (48-dim) ===
    col = hsv_histogram(roi_padded, bins=16, v_weight=0.6)  # 16*3 = 48
    
    # === 3. Depth Feature (256-dim) ===
    depth_feat = extract_depth_feature(box, depth_img)  # 16x16 grid
    depth_feat /= np.linalg.norm(depth_feat)
    
    # === 4. Weighted Concatenation ===
    emb_weighted = emb * (1.0 - color_weight)      # 70%
    col_weighted = col * color_weight              # 30%
    depth_weighted = depth_feat * 0.1              # 10%
    
    feat = np.concatenate([emb_weighted, col_weighted, depth_weighted])
    feat /= np.linalg.norm(feat)  # Final L2 normalize
    
    return feat  # Total: 1280 + 48 + 256 = 1584-dim
```

### 7.2 HSV Histogram

```python
def hsv_histogram(roi_bgr, bins=16, v_weight=0.5, normalize_brightness=True):
    hsv = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2HSV)
    
    # Normalize brightness (ch·ªëng ng∆∞·ª£c s√°ng)
    if normalize_brightness:
        v_channel = hsv[:,:,2]
        v_mean = v_channel.mean()
        if v_mean > 10:
            v_channel = np.clip(v_channel * (128.0 / v_mean), 0, 255)
            hsv[:,:,2] = v_channel
    
    # 3 histogram: H(16), S(16), V(16)
    histH = cv2.calcHist([hsv], [0], None, [bins], [0, 180])  # Hue
    histS = cv2.calcHist([hsv], [1], None, [bins], [0, 256])  # Saturation
    histV = cv2.calcHist([hsv], [2], None, [bins], [0, 256])  # Value
    
    histV *= v_weight  # Gi·∫£m ·∫£nh h∆∞·ªüng c·ªßa brightness
    
    h = np.concatenate([histH, histS, histV]).flatten()  # 48-dim
    h /= np.linalg.norm(h)
    return h
```

### 7.3 Depth Feature

```python
def extract_depth_feature(box, depth_img, target_size=(16, 16)):
    """
    T·∫°o depth map 16x16 t·ª´ bounding box.
    Gi√∫p ph√¢n bi·ªát ng∆∞·ªùi ·ªü kho·∫£ng c√°ch kh√°c nhau.
    """
    roi = depth_img[y1:y2, x1:x2]
    roi_resized = cv2.resize(roi, target_size)
    
    # Normalize: g·∫ßn ‚Üí 1.0, xa ‚Üí 0.0
    roi_normalized = np.clip((5000 - roi_resized) / 4500.0, 0.0, 1.0)
    
    return roi_normalized.flatten()  # 256-dim
```

---

## 8. Lu·ªìng X·ª≠ L√Ω Chi Ti·∫øt

### 8.1 Main Callback (on_image)

```mermaid
flowchart TB
    START[on_image callback] --> SKIP{Frame skip?}
    SKIP -->|Skip| END[Return]
    SKIP -->|Process| RESIZE[Resize frame 640x480]
    
    RESIZE --> DETECT[MobileNet-SSD detect]
    DETECT --> ENROLL{auto_done?}
    
    ENROLL -->|No| DO_ENROLL[auto_enroll_step]
    DO_ENROLL --> END
    
    ENROLL -->|Yes| FEATURES[Extract features<br/>for all detections]
    FEATURES --> DEEPSORT[deepsort.update]
    
    DEEPSORT --> STATE{state?}
    
    STATE -->|SEARCHING| FIND_REID[_find_best_track_by_reid]
    FIND_REID --> FOUND{Found?}
    FOUND -->|Yes| SET_LOCKED[state = LOCKED<br/>track_id = best_track.id]
    FOUND -->|No| PUB
    
    STATE -->|LOCKED| OCC{Occluded?}
    OCC -->|Yes| SET_LOST1[state = LOST]
    OCC -->|No| GET_TRACK[get_track_by_id]
    GET_TRACK --> TRACK_OK{Track OK?}
    TRACK_OK -->|Yes| UPDATE_BOX[Update target_box]
    TRACK_OK -->|No| TRY_REID1[Try ReID]
    TRY_REID1 --> REID_OK1{Found?}
    REID_OK1 -->|Yes| RE_ASSIGN[Re-assign track_id]
    REID_OK1 -->|No| SET_LOST2[state = LOST]
    
    STATE -->|LOST| KALMAN[Get Kalman prediction]
    KALMAN --> MATCHED{Track matched?}
    MATCHED -->|Yes| CHECK_SCORE{score > accept_thr?}
    CHECK_SCORE -->|Yes| REACQUIRE[state = LOCKED]
    MATCHED -->|No| TRY_REID2[Try ReID]
    TRY_REID2 --> REID_OK2{Found?}
    REID_OK2 -->|Yes| REACQUIRE
    REID_OK2 -->|No| GRACE{Grace expired?}
    GRACE -->|Yes| SET_SEARCH[state = SEARCHING]
    GRACE -->|No| PUB
    
    SET_LOCKED --> PUB
    UPDATE_BOX --> PUB
    RE_ASSIGN --> PUB
    SET_LOST1 --> PUB
    SET_LOST2 --> PUB
    REACQUIRE --> PUB
    SET_SEARCH --> PUB
    
    PUB[Publish cmd_vel, state, debug] --> END
```

### 8.2 Pseudo-code T·ªïng H·ª£p

```python
def on_image(msg):
    # 1. Pre-processing
    frame = resize(bridge.imgmsg_to_cv2(msg))
    depth_frame = resize(self.depth_img)
    
    # 2. Detection
    pboxes = detect_persons(frame, conf=0.4)
    
    # 3. Enrollment (if not done)
    if not self.auto_done:
        auto_enroll_step(frame, pboxes)
        return
    
    # 4. Feature extraction for all detections
    features = [enhanced_body_feature(frame, box, depth) for box in pboxes]
    
    # 5. DeepSORT update
    tracks = deepsort.update(pboxes, features)
    confirmed_tracks = deepsort.get_confirmed_tracks()
    
    # 6. State machine
    if state == 'SEARCHING':
        best = _find_best_track_by_reid(confirmed_tracks)
        if best:
            state = 'LOCKED'
            track_id = best.track_id
            
    elif state == 'LOCKED':
        if is_occluded():
            state = 'LOST'
        else:
            track = deepsort.get_track_by_id(track_id)
            if track and not track.is_deleted():
                target_box = track.to_tlbr()
                similarity = dot(track.get_feature(), target_feature)
                if similarity < reject_thr:
                    state = 'LOST'
            else:
                # Try ReID
                best = _find_best_track_by_reid(confirmed_tracks)
                if best:
                    track_id = best.track_id
                else:
                    state = 'LOST'
                    
    elif state == 'LOST':
        track = deepsort.get_track_by_id(track_id)
        if track and not track.is_deleted():
            target_box = track.to_tlbr()  # Kalman prediction
            if track.time_since_update == 0:  # Matched
                score = dot(track.get_feature(), target_feature)
                if score > accept_thr:
                    state = 'LOCKED'
        else:
            best = _find_best_track_by_reid(confirmed_tracks)
            if best:
                state = 'LOCKED'
                track_id = best.track_id
        
        if time.time() - lost_start > grace_period:
            state = 'SEARCHING'
    
    # 7. Control & Publishing
    twist = compute_cmd(target_box)
    cmd_pub.publish(twist)
    state_pub.publish(state)
```

---

## 9. Tham S·ªë C·∫•u H√¨nh

### 9.1 DeepSORT Parameters

| Tham s·ªë | Gi√° tr·ªã | M√¥ t·∫£ |
|---------|---------|-------|
| `max_age` | 30 | S·ªë frame gi·ªØ track khi kh√¥ng match |
| `n_init` | 3 | S·ªë hits ƒë·ªÉ confirm track |
| `max_cosine_distance` | 0.4 | Ng∆∞·ª°ng appearance matching |
| `lambda_weight` | 0.3 | Tr·ªçng s·ªë motion (0.3) vs appearance (0.7) |

### 9.2 State Machine Parameters

| Tham s·ªë | Gi√° tr·ªã | M√¥ t·∫£ |
|---------|---------|-------|
| `accept_threshold` | 0.75 | Ng∆∞·ª°ng ƒë·ªÉ ch·∫•p nh·∫≠n target |
| `reject_threshold` | 0.60 | Ng∆∞·ª°ng ƒë·ªÉ t·ª´ ch·ªëi (m·∫•t target) |
| `grace_period_sec` | 2.0 | Th·ªùi gian ch·ªù tr∆∞·ªõc khi SEARCHING |
| `occlusion_threshold` | 0.5 | Ng∆∞·ª°ng depth ƒë·ªÉ ph√°t hi·ªán occlusion |

### 9.3 ReID Parameters

| Tham s·ªë | Gi√° tr·ªã | M√¥ t·∫£ |
|---------|---------|-------|
| `body_color_weight` | 0.22 | Tr·ªçng s·ªë m√†u s·∫Øc trong feature |
| `hsv_normalize_brightness` | True | Normalize brightness (ch·ªëng ch√≥i) |
| `iou_threshold` | 0.4 | Ng∆∞·ª°ng IoU cho matching |

### 9.4 Control Parameters

| Tham s·ªë | Gi√° tr·ªã | M√¥ t·∫£ |
|---------|---------|-------|
| `target_distance_m` | 2.0 | Kho·∫£ng c√°ch mong mu·ªën (m) |
| `kd_distance` | 0.6 | H·ªá s·ªë P cho distance control |
| `kx_center` | 0.00025 | H·ªá s·ªë P cho heading control |
| `center_deadband_px` | 40 | V√πng ch·∫øt (pixel) |

---

## üéØ T√≥m T·∫Øt

### ∆Øu ƒêi·ªÉm c·ªßa DeepSORT

1. ‚úÖ **Kalman Filter**: D·ª± ƒëo√°n v·ªã tr√≠ khi m·∫•t detection
2. ‚úÖ **Feature History**: Matching robust qua th·ªùi gian
3. ‚úÖ **Cascade Matching**: ∆Øu ti√™n confirmed tracks
4. ‚úÖ **Track ID**: Follow target d√π position thay ƒë·ªïi
5. ‚úÖ **Occlusion Handling**: Re-acquire b·∫±ng ReID

### So S√°nh v·ªõi CSRT (c≈©)

| Ti√™u ch√≠ | CSRT | DeepSORT |
|----------|------|----------|
| Motion model | ‚ùå Kh√¥ng | ‚úÖ Kalman 8-dim |
| Velocity tracking | ‚ùå | ‚úÖ |
| Re-ID | ‚ùå Template matching | ‚úÖ Feature history |
| Occlusion | ‚≠ê K√©m | ‚≠ê‚≠ê‚≠ê‚≠ê T·ªët |
| Multi-target | ‚ùå Single | ‚úÖ Multi (ch·ªâ follow 1) |
| CPU usage | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê (h∆°i n·∫∑ng h∆°n) |

---

*Document created: 17/12/2024*
